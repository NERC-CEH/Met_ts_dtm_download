{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and process some Nextmap tiles from the CEDA archive\n",
    "\n",
    "\n",
    "**Ensure you are running the correct kernel. Look at the top right  it should be [conda env:eot] as seen in the top right.** \n",
    "\n",
    "**If not, Kernel > Change kernel > eot from the menu.** \n",
    "\n",
    "The example is running on countryside survey data which may be accessed via the CEH environmental data centre. \n",
    "\n",
    "https://eip.ceh.ac.uk/\n",
    "\n",
    "The data is returned as a dataframe as well as written to file and can be easily plotted using pandas native functions. \n",
    "\n",
    "If you wish to see how this has been done, please look at the files in src."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.downloader import  dtmftp_mt\n",
    "from src.utils import batch_translate_adf, batch_gdaldem, replace_str, zonal_point\n",
    "import geopandas as gpd\n",
    "import os\n",
    "from shutil import rmtree\n",
    "from glob2 import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We need a load of OS grid tiles that contain the CSS survey plots.\n",
    "\n",
    "This is most easily done with QGIS via Processing > Vector selection > Extract by location.\n",
    "\n",
    "I used the a public 10km OSGB grid dataset to achieve this which is in this repo \n",
    "(osgb10kmgrid.shp)\n",
    "\n",
    "A polygon from that operation will be used here to provide the names for the download.\n",
    "\n",
    "**Please generate your own as the CSS poly can't be uploaded here.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inShp = 'path/to/CSS/shp'\n",
    "\n",
    "gdf = gpd.read_file(inShp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we extract the tile names from the gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tilenms = gdf[\"TILE_NAME\"].tolist()\n",
    "\n",
    "tilenms[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input/output admin\n",
    "\n",
    "Some messing around is needed first to input the correct info into the download function. I have just copied the url from one dataset from ceda website and will alter it quickly here to create inputs to bulk download it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"ftp://ftp.ceda.ac.uk/neodc/nextmap/by_tile/hp/hp40/dtm/hp40dtm/\"\n",
    "\n",
    "#the tile ids must be lower case\n",
    "tilenms = [t.lower() for t in tilenms]\n",
    "\n",
    "# insert the tileid for every item\n",
    "dwnurls = [replace_str(template, t) for t in tilenms]\n",
    "\n",
    "# the url has to have the ftp part removed\n",
    "ftplist = [d.replace(\"ftp://ftp.ceda.ac.uk/\", \"\") for d in dwnurls]\n",
    "\n",
    "# example\n",
    "ftplist[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download\n",
    "\n",
    "Unfortunately CEDA's DAP server is not currently working for this dataset, meaning we have to resort to rather arcane FTP methods. The function below downloads data in parallel using ftplib.\n",
    "\n",
    "Enter you user and password below to use this as with previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = \"\"\n",
    "passwd =\"\"\n",
    "\n",
    "# download to here unless specified\n",
    "main_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This will take a while! Best to go do something!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outpaths = dtmftp_mt(user, passwd, ftplist, main_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate & tidy up\n",
    "\n",
    "Unfortunately this data arrives in ESRI binary grid format, so best to convert it to something better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the binary grid dirs\n",
    "dirlist = glob(os.path.join(os.getcwd(), '*dtm'))\n",
    "# add the header\n",
    "inlist = [os.path.join(d, 'hdr.adf') for d in dirlist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translate....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtms = batch_translate_adf(inlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove ESRI garbage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = [rmtree(d) for d in dirlist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build a virtual raster of the DTMs (A ```!``` denotes cmd line use)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdalbuildvrt cssDTM.vrt *.tif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now calculate aspect and slope for each dtm\n",
    "\n",
    "It would of course be inefficient mosaic then calculate aspect etc so we loop through them all and build virtual rasters at the end.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspects = batch_gdaldem(dtms, prop='aspect')\n",
    "\n",
    "slopes = batch_gdaldem(dtms, prop='slope')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct virtual rasters of each using the gdal command line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdalbuildvrt cssAspect.vrt *aspect.tif\n",
    "\n",
    "!gdalbuildvrt cssSlope.vrt *slope.tif\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribute CSS points\n",
    "\n",
    "Now all that is required is a zonal point for each CSS plot.\n",
    "\n",
    "Here the parameters are (in order) the input point file, input raster and the field name that will record the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zonal_point(inShp, 'cssAspect.vrt', 'dtm-aspect')\n",
    "\n",
    "zonal_point(inShp, 'cssSlope.vrt', 'dtm-slope')\n",
    "\n",
    "zonal_point(inShp, 'cssDTM.vrt', 'dtm-elev')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gee]",
   "language": "python",
   "name": "conda-env-gee-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
